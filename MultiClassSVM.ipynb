{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Multiclass_SVM import MultiSVM,np\n",
    "from pyspark import SparkContext,SparkConf\n",
    "from sklearn.base import copy\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-b8fd4c8de6c9>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\Manav\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\Manav\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Manav\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Manav\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_in(x,svm,classes):\n",
    "    for it in x:\n",
    "        X=it[:-1].reshape(1,it.shape[0]-1)\n",
    "        y=np.array([it[-1]])\n",
    "        y=y.astype('int')\n",
    "        svm.partial_fit(X,y,classes)\n",
    "    yield svm\n",
    "def update_in(m1,m2):\n",
    "    new_mod=copy.deepcopy(m1)\n",
    "    new_mod.coefs+=m2.coefs\n",
    "    new_mod.intercept+=m2.intercept\n",
    "    return new_mod\n",
    "\n",
    "def avg_coefs_in(svm,numpart):\n",
    "    svm.coefs/=numpart\n",
    "    svm.intercept/=numpart\n",
    "    return svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=SparkConf().setAppName(\"MultiSVM-SGD\").setMaster('local[4]')\n",
    "sc=SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=mnist.train.images[:10000,:]\n",
    "y=mnist.train.labels[:10000]\n",
    "X=np.hstack((X,y.reshape((y.shape[0],1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter=250\n",
    "svm=MultiSVM(l=0.0001)\n",
    "n_classes=np.unique(y).shape[0]\n",
    "prev_coef=np.zeros((n_classes,X.shape[1]-1))\n",
    "prev_intercept=np.zeros(n_classes)\n",
    "tol=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[-0.4975 -0.5775  0.3175 -0.6875  0.275   2.3375 -0.6475  1.485  -1.5575\n",
      " -0.4475]\n"
     ]
    }
   ],
   "source": [
    "for i in range(max_iter):\n",
    "    dat=sc.parallelize(X)\n",
    "    svm=dat.mapPartitions(lambda x:fit_in(x,svm,n_classes)).reduce(lambda m1,m2:update_in(m1,m2))\n",
    "    svm=avg_coefs_in(svm,dat.getNumPartitions())\n",
    "    diff_coef=svm.coefs-prev_coef\n",
    "    diff_intercept=svm.intercept-prev_intercept\n",
    "    coef_norm=np.linalg.norm(diff_coef,ord='fro')**2\n",
    "    gradient_sum=np.sqrt(coef_norm+np.sum(diff_intercept**2))\n",
    "    if gradient_sum<tol:\n",
    "        break\n",
    "    prev_coef=svm.coefs\n",
    "    prev_intercept=svm.intercept\n",
    "    np.random.shuffle(X)\n",
    "print(svm.coefs)\n",
    "print(svm.intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=5*np.random.random((400,2))-3\n",
    "y1=0*np.ones(X1.shape[0])\n",
    "X2=6*(np.random.random((400,2)))+7\n",
    "y2=np.ones(X2.shape[0])\n",
    "X3=25*(np.random.random((400,2)))+20\n",
    "y3=2*np.ones(X2.shape[0])\n",
    "y=np.hstack((y1,y2,y3))\n",
    "X=np.vstack((X1,X2,X3))\n",
    "y=y.reshape(y.shape[0],1)\n",
    "X=np.hstack((X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.predict(X[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -0.41626969,   2.41882535,   2.98104061, ...,  -4.7069067 ,\n",
       "          8.38391854,   2.32072387],\n",
       "       [ -6.33236063,   7.06645323,   3.32200786, ...,  -0.76602734,\n",
       "          2.42033267,  -0.75587957],\n",
       "       [  2.8272625 , -13.79380218,  16.5408056 , ...,   0.32003107,\n",
       "         -0.39485462,  -2.73944811],\n",
       "       ...,\n",
       "       [ -3.35433523,  -4.15712646,  -1.3338482 , ...,  12.50814927,\n",
       "          2.52833762,   7.6241167 ],\n",
       "       [ -4.5692111 ,  -8.63654805,   5.08905853, ...,   0.03290686,\n",
       "         10.58070074,   3.50060918],\n",
       "       [ -2.06975151,   0.88825057,  -1.21010485, ...,  -2.24074222,\n",
       "          7.59434841,   1.60494859]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.support_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9966"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(svm.predictions==X[:,-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
